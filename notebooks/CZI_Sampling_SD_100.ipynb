{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import ast\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tempfile\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "DATA_DIR_PATH = '../data/czi-software-mentions'\n",
    "RAW_FILE_PATH = f'{DATA_DIR_PATH}/raw.tar.gz'\n",
    "LINKED_FILE_PATH = f'{DATA_DIR_PATH}/linked.tar.gz'\n",
    "RAW_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822384\"\n",
    "LINKED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822388\"\n",
    "# DISAMBIGUATED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822387\"\n",
    "\n",
    "def remove_empty_spaces(dic):\n",
    "    \"\"\" Function removing an empty space at the first position of a string. \n",
    "    \"\"\"\n",
    "    for i in dic:\n",
    "        if dic[i][:1] == \" \":\n",
    "            dic[i] = dic[i].strip()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data directory and check if files exist to avoid duplicate large downloads\n",
    "raw_exists = False\n",
    "linked_exists = False\n",
    "try:\n",
    "    os.makedirs(DATA_DIR_PATH)\n",
    "except FileExistsError:\n",
    "    raw_exists = os.path.isfile(RAW_FILE_PATH)\n",
    "    linked_exists = os.path.isfile(LINKED_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a progressbar to track download progress\n",
    "import progressbar\n",
    "\n",
    "class DownloadProgressBar():\n",
    "    def __init__(self):\n",
    "        self.pbar = None\n",
    "\n",
    "    def __call__(self, block_num, block_size, total_size):\n",
    "        if not self.pbar:\n",
    "            self.pbar=progressbar.ProgressBar(maxval=total_size)\n",
    "            self.pbar.start()\n",
    "\n",
    "        downloaded = block_num * block_size\n",
    "        if downloaded < total_size:\n",
    "            self.pbar.update(downloaded)\n",
    "        else:\n",
    "            self.pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd50143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from CZI dataset into data directory\n",
    "if not linked_exists:\n",
    "    urllib.request.urlretrieve(LINKED_TAR_URL, LINKED_FILE_PATH, DownloadProgressBar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not raw_exists:\n",
    "    urllib.request.urlretrieve(RAW_TAR_URL, RAW_FILE_PATH, DownloadProgressBar())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset tarballs\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(RAW_FILE_PATH) as raw_tar:\n",
    "    raw_tar.extractall(f'{DATA_DIR_PATH}/raw/')\n",
    "with tarfile.open(LINKED_FILE_PATH) as linked_tar:\n",
    "    linked_tar.extractall(f'{DATA_DIR_PATH}/linked/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gunzip needed files\n",
    "import gzip\n",
    "import shutil\n",
    "for gzip_file in [\n",
    "    f'{DATA_DIR_PATH}/raw/raw/comm_raw.tsv.gz',\n",
    "    f'{DATA_DIR_PATH}/raw/raw/non_comm_raw.tsv.gz',\n",
    "    f'{DATA_DIR_PATH}/raw/raw/publishers_collections_raw.tsv.gz',\n",
    "]:\n",
    "    with gzip.open(gzip_file, 'rb') as f_in:\n",
    "        with open(gzip_file[:-3], 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500254ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the data and basic cleaning\n",
    "# Use dask, as we're dealing with potentially larger-than-memory data (e.g. the raw publishers mentions dataset has 10+GB)\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Read TSV into a single dataframe, brute-force mapping all values to strings\n",
    "df_czi = dd.concat([\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/comm_raw.tsv', sep='\\t', converters={i: str for i in range(14770211)}),\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/non_comm_raw.tsv', sep='\\t', converters={i: str for i in range(4546609)}),\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/publishers_collections_raw.tsv', sep='\\t', converters={i: str for i in range(42868907)})\n",
    "],\n",
    "ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "software = df_czi.software\n",
    "software = software.explode()\n",
    "software = software.str.replace('\\'', '')\n",
    "software.value_counts(dropna=False)\n",
    "\n",
    "software_dict = software.compute()\n",
    "# software_dict = remove_empty_spaces(software_dict)\n",
    "software_series = pd.Series(software_dict)\n",
    "\n",
    "#This is what our data looks like on a log scale\n",
    "#Approx 100k software\n",
    "#Approx 600k mentions\n",
    "#Note around half the data has 1 citation, around 8% >10 citations, less than 1.5% have >50\n",
    "plt.hist(software_series.value_counts(),bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "# print(len(software_dict))\n",
    "plt.savefig(f'{DATA_DIR_PATH}/citation_histogram.png')\n",
    "with open(f'{DATA_DIR_PATH}/len_software_dict', 'w') as lenf:\n",
    "    lenf.write(str(len(software_dict)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the whole humungous dataframe to a single file\n",
    "df_czi.to_csv(f\"{DATA_DIR_PATH}/czi.csv\", index=False, encoding='utf-8-sig', single_file=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random sample of data, and save as CSV\n",
    "\n",
    "SAMPLE_COUNT = 100\n",
    "\n",
    "i = 0\n",
    "with open(f\"{DATA_DIR_PATH}/czi.csv\", 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    row_count = sum(1 for row in csv_reader)\n",
    "    rand_ints = random.sample(range(1, row_count), SAMPLE_COUNT)\n",
    "    with open(f\"{DATA_DIR_PATH}/czi_output_random_100.csv\", 'w') as output:\n",
    "        output_writer = csv.writer(output, delimiter=',')\n",
    "        csv_file.seek(0)\n",
    "        for row in csv_reader:\n",
    "            if i == 0 or i in rand_ints:\n",
    "                output_writer.writerow(row)\n",
    "            i += 1\n",
    "            \n",
    "CZI_CSV = pd.read_csv(f\"{DATA_DIR_PATH}/czi_output_random_100.csv\")\n",
    "software = CZI_CSV.software\n",
    "software = software.explode(ignore_index = True)\n",
    "software = software.str.replace('\\'', '')\n",
    "software.value_counts(dropna=False)\n",
    "software_dict = software.to_dict()\n",
    "software_dict = remove_empty_spaces(software_dict)\n",
    "software_series_sample = pd.Series(software_dict)\n",
    "plt.hist(software_series_sample.value_counts(),bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/sample_citation_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c99134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Population is non-normal so to test variances use Levene's test \n",
    "#https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
    "\n",
    "from scipy.stats import levene\n",
    "stat,p=levene(software_series.value_counts(), software_series_sample.value_counts())\n",
    "print(p)\n",
    "#Actual values of variances\n",
    "[np.var(x, ddof=1) for x in [software_series.value_counts(), software_series_sample.value_counts()]]\n",
    "with open(f'{DATA_DIR_PATH}/p_values', 'w') as pf:\n",
    "    pf.write(f'p: {str(p)}\\n{str([np.var(x, ddof=1) for x in [software_series.value_counts(), software_series_sample.value_counts()]])}')\n",
    "#Gives small p-values, populations don't have equal variances (unsurprisingly...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can create stratified sample, here the y data are bins to split the #citations. Visually it's not so different from the fully random sample.\n",
    "y=(np.linspace(0,0.999999999999,len(software.value_counts()))*1000).astype(int)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(software.value_counts(), y,stratify=y, test_size=1000)\n",
    "plt.hist(X_test, bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/test_split.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33428a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does a sample look like the original (with actual tests as well as visually) if we exclude the top 10 cited?\n",
    "# -> Sometimes\n",
    "\n",
    "df_val_counts = pd.DataFrame(software.value_counts())\n",
    "df_top10=df_val_counts.nlargest(10,'software')\n",
    "df_without_top10=df_val_counts.nsmallest(len(df_val_counts)-10,'software')\n",
    "sample_100=df_without_top10.sample(100)\n",
    "\n",
    "\n",
    "from scipy.stats import levene\n",
    "stat,p=levene(df_without_top10.software, sample_100.software)\n",
    "print(p)\n",
    "#Actual values of variances\n",
    "print([np.var(x, ddof=1) for x in [df_without_top10.software, sample_100.software]])\n",
    "\n",
    "with open(f'{DATA_DIR_PATH}/variance', 'w') as pf:\n",
    "    pf.write(f'p: {str(p)}\\n{str([np.var(x, ddof=1) for x in [df_without_top10.software, sample_100.software]])}')\n",
    "\n",
    "#Save these as our sample:\n",
    "\n",
    "sample_100.to_csv(f'{DATA_DIR_PATH}/100sample_without_top_10.csv',index=False)\n",
    "df_top10.to_csv(f'{DATA_DIR_PATH}/top_10.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac653e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
