{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import urllib.request\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('.') / '.czi.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# Configure the data dir path in .czi.env located in this directory\n",
    "DATA_DIR_PATH = os.environ.get(\"DATA_DIR_PATH\")\n",
    "print(f'Using data directory {DATA_DIR_PATH}')\n",
    "\n",
    "\n",
    "RAW_FILE_PATH = f'{DATA_DIR_PATH}/raw.tar.gz'\n",
    "LINKED_FILE_PATH = f'{DATA_DIR_PATH}/linked.tar.gz'\n",
    "RAW_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822384\"\n",
    "LINKED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822388\"\n",
    "# DISAMBIGUATED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822387\"\n",
    "\n",
    "FILTERED_CZI_SOFTWARE_CSV = 'czi_software.csv'\n",
    "SAMPLED_1000_CZI_CSV = 'sample_1000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c99134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population is non-normal (see czi_random_10000_histogram.png) so to test variances use Levene's test,\n",
    "# Comparing the equality of variance between the full dataset and the sample\n",
    "# https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Read TSV into a single dataframe, brute-force mapping all values to strings\n",
    "df_filtered_czi = dd.read_csv(f'{DATA_DIR_PATH}/{FILTERED_CZI_SOFTWARE_CSV}')\n",
    "df_sample = dd.read_csv(f\"{DATA_DIR_PATH}/{SAMPLED_1000_CZI_CSV}\")\n",
    "\n",
    "df_filtered_czi = df_filtered_czi.set_index()\n",
    "full_counts = df_filtered_czi.software.value_counts()\n",
    "sample_counts = df_sample.software.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can create stratified sample, here the y data are bins to split the #citations. Visually it's not so different from the fully random sample.\n",
    "\n",
    "# First, re-read the software column from the complete dataset into a Series\n",
    "# czi_software_df = pd.read_csv(f'{DATA_DIR_PATH}/czi_software.csv', usecols=['software'])\n",
    "# czi_software_df.reset_index()\n",
    "# full_software_series = czi_software_df.software\n",
    "\n",
    "# Compare the original software series and this series and save the comparison result\n",
    "# pd_series_len = full_software_series.size\n",
    "# dd_series_len = software_series.size.compute()\n",
    "# with open(f'{DATA_DIR_PATH}/series_comparison', 'w') as cf:\n",
    "#     cf.write(f'Reread series size: {pd_series_len} | Dask series size: {dd_series_len}')\n",
    "\n",
    "y=(np.linspace(0,0.999999999999,len(full_counts))*1000).astype(int)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_counts, y,stratify=y, test_size=1000)\n",
    "plt.hist(X_test, bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/czi_stratified_sample_histogram.png')\n",
    "# Compare with czi_random_stratified_sample_1000_citation_histogram.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33428a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the sampled 1000 from the original sample of 10000 look like the original (with actual tests as well as visually) if we exclude the top 100 cited?\n",
    "# -> Sometimes\n",
    "\n",
    "\n",
    "\n",
    "# df_val_counts = pd.DataFrame(software_series_sample.value_counts())\n",
    "# df_val_counts = df_val_counts.reset_index()\n",
    "df_top100 = df_sample.nlargest(100,'mention_counts')\n",
    "df_900_without_top100 = df_sample.nsmallest(900,'mention_counts')\n",
    "\n",
    "df_top100.to_csv(f'{DATA_DIR_PATH}/CZI_sample_top_100.csv',index=True)\n",
    "df_900_without_top100.to_csv(f'{DATA_DIR_PATH}/CZI_sample_900_without_top_100.csv',index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac653e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare linking by reading in the mention IDs from the random sample\n",
    "#import csv\n",
    "\n",
    "#ids = []\n",
    "\n",
    "#with open(f'{DATA_DIR_PATH}/czi_output_random_100.csv', 'r') as csvin:\n",
    "#    csvr = csv.DictReader(csvin, delimiter=',')\n",
    "#    for row in csvr:\n",
    "#        ids.append(row['ID'])\n",
    "#        # print(row)\n",
    "#ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_files = [\n",
    "#    'bioconductor_df.csv',\n",
    "#    'cran_df.csv',\n",
    "#    'github_df.csv',\n",
    "#    'pypi_df.csv',\n",
    "#    'scicrunch_df.csv'\n",
    "#]\n",
    "#\n",
    "#lines = []\n",
    "#\n",
    "#import sys\n",
    "#maxInt = sys.maxsize\n",
    "#\n",
    "#while True:\n",
    "    # decrease the maxInt value by factor 10\n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "#    try:\n",
    "#        csv.field_size_limit(maxInt)\n",
    "#        break\n",
    "#    except OverflowError:\n",
    "#        maxInt = int(maxInt/10)\n",
    "\n",
    "#def extract_links(lf, _id):\n",
    "#    with open(f'{DATA_DIR_PATH}/linked/linked/normalized/{lf}', 'r') as csvfile:\n",
    "#        datareader = csv.DictReader(csvfile)\n",
    "#        for row in datareader:\n",
    "#            if row['ID'] == _id:\n",
    "#                yield row\n",
    "\n",
    "#for lf in linked_files:\n",
    "#    for _id in ids:\n",
    "#        for huh in extract_links(lf, _id):\n",
    "#            lines.append(huh)\n",
    "\n",
    "#lines\n",
    "\n",
    "# df = dd.read_csv(\"/home/stephan/src/habeas-corpus/data/czi-software-mentions/linked/linked/normalized/bioconductor_df.csv\")\n",
    "# print(f'EMPTY? {len(df.index)}')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_lines = []\n",
    "\n",
    "#with open(f'{DATA_DIR_PATH}/czi_output_random_100.csv', 'r', encoding='utf-8-sig') as csvin:\n",
    "#    csvr = csv.DictReader(csvin, delimiter=',')\n",
    "#    for row in csvr:\n",
    "#        _id = row['ID']\n",
    "#        for line in lines:\n",
    "#            if line['ID'] == _id:\n",
    "#                linked_line = row | line\n",
    "#                linked_lines.append(linked_line)\n",
    "#                continue\n",
    "#        linked_lines.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ceb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#\n",
    "#interim_df = pd.read_json(json.dumps(linked_lines))\n",
    "#interim_df.to_csv(f'{DATA_DIR_PATH}/CZI_sample_1000_without_top_100_linked.csv', encoding='utf-8', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f91c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
