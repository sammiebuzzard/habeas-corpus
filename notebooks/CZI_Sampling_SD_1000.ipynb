{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import urllib.request\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('.') / '.czi.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# Configure the data dir path in .czi.env located in this directory\n",
    "DATA_DIR_PATH = os.environ.get(\"DATA_DIR_PATH\")\n",
    "print(f'Using data directory {DATA_DIR_PATH}')\n",
    "\n",
    "\n",
    "RAW_FILE_PATH = f'{DATA_DIR_PATH}/raw.tar.gz'\n",
    "LINKED_FILE_PATH = f'{DATA_DIR_PATH}/linked.tar.gz'\n",
    "RAW_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822384\"\n",
    "LINKED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822388\"\n",
    "# DISAMBIGUATED_TAR_URL = \"https://datadryad.org/stash/downloads/file_stream/1822387\"\n",
    "\n",
    "FILTERED_CZI_SOFTWARE_CSV = 'czi_software.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data directory and check if files exist to avoid duplicate large downloads\n",
    "raw_exists = False\n",
    "linked_exists = False\n",
    "try:\n",
    "    os.makedirs(DATA_DIR_PATH)\n",
    "except FileExistsError:\n",
    "    raw_exists = os.path.isfile(RAW_FILE_PATH)\n",
    "    linked_exists = os.path.isfile(LINKED_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a progressbar to track download progress\n",
    "import progressbar\n",
    "\n",
    "class DownloadProgressBar():\n",
    "    def __init__(self):\n",
    "        self.pbar = None\n",
    "\n",
    "    def __call__(self, block_num, block_size, total_size):\n",
    "        if not self.pbar:\n",
    "            self.pbar=progressbar.ProgressBar(maxval=total_size)\n",
    "            self.pbar.start()\n",
    "\n",
    "        downloaded = block_num * block_size\n",
    "        if downloaded < total_size:\n",
    "            self.pbar.update(downloaded)\n",
    "        else:\n",
    "            self.pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd50143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from CZI dataset into data directory\n",
    "if not linked_exists:\n",
    "    urllib.request.urlretrieve(LINKED_TAR_URL, LINKED_FILE_PATH, DownloadProgressBar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_exists:\n",
    "    urllib.request.urlretrieve(RAW_TAR_URL, RAW_FILE_PATH, DownloadProgressBar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset tarballs\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(RAW_FILE_PATH) as raw_tar:\n",
    "    raw_tar.extractall(f'{DATA_DIR_PATH}/raw/')\n",
    "with tarfile.open(LINKED_FILE_PATH) as linked_tar:\n",
    "    linked_tar.extractall(f'{DATA_DIR_PATH}/linked/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gunzip needed files\n",
    "import gzip\n",
    "import shutil\n",
    "for gzip_file in [\n",
    "    f'{DATA_DIR_PATH}/raw/raw/comm_raw.tsv.gz',\n",
    "    f'{DATA_DIR_PATH}/raw/raw/non_comm_raw.tsv.gz',\n",
    "    f'{DATA_DIR_PATH}/raw/raw/publishers_collections_raw.tsv.gz',\n",
    "]:\n",
    "    with gzip.open(gzip_file, 'rb') as f_in:\n",
    "        with open(gzip_file[:-3], 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500254ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the data and basic cleaning\n",
    "# Use dask, as we're dealing with potentially larger-than-memory data (e.g. the raw publishers mentions dataset has 10+GB)\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Read TSV into a single dataframe, brute-force mapping all values to strings\n",
    "df_czi = dd.concat([\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/comm_raw.tsv', sep='\\t', converters={i: str for i in range(14771000)}),\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/non_comm_raw.tsv', sep='\\t', converters={i: str for i in range(4547000)}),\n",
    "    dd.read_csv(f'{DATA_DIR_PATH}/raw/raw/publishers_collections_raw.tsv', sep='\\t', converters={i: str for i in range(48165000)})\n",
    "],\n",
    "ignore_index=True)\n",
    "\n",
    "# Filter only curated software\n",
    "df_filtered_czi = df_czi.loc[df_czi['curation_label'] == 'software']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a85534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of just the software names\n",
    "software_series = df_filtered_czi.software\n",
    "\n",
    "# A Series of unqiue value counts for the software column\n",
    "software_counts = software_series.value_counts(dropna=False)\n",
    "\n",
    "#This is what our data looks like on a log scale\n",
    "plt.hist(software_counts,bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/czi_full_citation_histogram.png')\n",
    "with open(f'{DATA_DIR_PATH}/software_mentions_total', 'w') as tf:\n",
    "    tf.write(str(software_series.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole humungous dataframe to a single file\n",
    "df_filtered_czi.to_csv(f\"{DATA_DIR_PATH}/{FILTERED_CZI_SOFTWARE_CSV}\", index=True, encoding='utf-8-sig', single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random sample of 10k data, and save as CSV\n",
    "\n",
    "SAMPLE_COUNT = 10000\n",
    "\n",
    "i = 0\n",
    "with open(f\"{DATA_DIR_PATH}/{FILTERED_CZI_SOFTWARE_CSV}\", 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    row_count = sum(1 for row in csv_reader)\n",
    "    rand_ints = random.sample(range(1, row_count), SAMPLE_COUNT)\n",
    "    with open(f\"{DATA_DIR_PATH}/czi_output_random_10000.csv\", 'w') as output:\n",
    "        output_writer = csv.writer(output, delimiter=',')\n",
    "        csv_file.seek(0)\n",
    "        for row in csv_reader:\n",
    "            if i == 0 or i in rand_ints:\n",
    "                output_writer.writerow(row)\n",
    "            i += 1\n",
    "            \n",
    "CZI_CSV = pd.read_csv(f\"{DATA_DIR_PATH}/czi_output_random_10000.csv\")\n",
    "software_series_sample = CZI_CSV.software\n",
    "\n",
    "\n",
    "plt.hist(software_series_sample.value_counts(),bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/czi_random_10000_citation_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c99134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population is non-normal (see czi_random_10000_histogram.png) so to test variances use Levene's test,\n",
    "# Comparing the equality of variance between the full dataset and the sample\n",
    "# https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
    "\n",
    "from scipy.stats import levene\n",
    "stat,p=levene(software_series.value_counts(), software_series_sample.value_counts())\n",
    "print(p)\n",
    "#Actual values of variances\n",
    "varval = [np.var(x, ddof=1) for x in [software_series.value_counts(), software_series_sample.value_counts()]]\n",
    "\n",
    "\n",
    "with open(f'{DATA_DIR_PATH}/population_p_values', 'w') as pf:\n",
    "    pf.write(f'p: {str(p)}\\n{str(varval)}')\n",
    "\n",
    "# If this gives small p-values, populations don't have equal variances (to be expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can create stratified sample, here the y data are bins to split the #citations. Visually it's not so different from the fully random sample.\n",
    "y=(np.linspace(0,0.999999999999,len(software_series.value_counts()))*1000).astype(int)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(software_series.value_counts(), y,stratify=y, test_size=1000)\n",
    "plt.hist(X_test, bins=1000)\n",
    "plt.yscale('log', nonpositive='clip')\n",
    "plt.savefig(f'{DATA_DIR_PATH}/czi_stratified_sample_histogram.png')\n",
    "# Compare with czi_random_10000_citation_histogram.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33428a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does a sample look like the original (with actual tests as well as visually) if we exclude the top 100 cited?\n",
    "# -> Sometimes\n",
    "\n",
    "df_val_counts = pd.DataFrame(software_series_sample.value_counts())\n",
    "df_val_counts = df_val_counts.reset_index()\n",
    "df_top100=df_val_counts.nlargest(100,'count')\n",
    "df_without_top100=df_val_counts.nsmallest(len(df_val_counts)-100,'count')\n",
    "sample_1000=df_without_top100.sample(1000)\n",
    "\n",
    "# Prepare Series for Levene test\n",
    "wo_top_100_series = df_without_top100.software\n",
    "sample_1000_series = sample_1000.software\n",
    "\n",
    "\n",
    "from scipy.stats import levene\n",
    "stat,p=levene(wo_top_100_series.value_counts(), sample_1000_series.value_counts())\n",
    "print(p)\n",
    "#Actual values of variances\n",
    "varval = [np.var(x, ddof=1) for x in [wo_top_100_series.value_counts(), sample_1000_series.value_counts()]]\n",
    "\n",
    "with open(f'{DATA_DIR_PATH}/sample_p_values', 'w') as pf:\n",
    "    pf.write(f'p: {str(p)}\\n{str(varval)}')\n",
    "\n",
    "#Save these as our sample:\n",
    "\n",
    "sample_1000.to_csv(f'{DATA_DIR_PATH}/CZI_sample_1000_without_top_100.csv',index=True)\n",
    "df_top100.to_csv(f'{DATA_DIR_PATH}/CZI_sample_top_100.csv',index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac653e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare linking by reading in the mention IDs from the random sample\n",
    "#import csv\n",
    "\n",
    "#ids = []\n",
    "\n",
    "#with open(f'{DATA_DIR_PATH}/czi_output_random_100.csv', 'r') as csvin:\n",
    "#    csvr = csv.DictReader(csvin, delimiter=',')\n",
    "#    for row in csvr:\n",
    "#        ids.append(row['ID'])\n",
    "#        # print(row)\n",
    "#ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_files = [\n",
    "#    'bioconductor_df.csv',\n",
    "#    'cran_df.csv',\n",
    "#    'github_df.csv',\n",
    "#    'pypi_df.csv',\n",
    "#    'scicrunch_df.csv'\n",
    "#]\n",
    "#\n",
    "#lines = []\n",
    "#\n",
    "#import sys\n",
    "#maxInt = sys.maxsize\n",
    "#\n",
    "#while True:\n",
    "    # decrease the maxInt value by factor 10\n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "#    try:\n",
    "#        csv.field_size_limit(maxInt)\n",
    "#        break\n",
    "#    except OverflowError:\n",
    "#        maxInt = int(maxInt/10)\n",
    "\n",
    "#def extract_links(lf, _id):\n",
    "#    with open(f'{DATA_DIR_PATH}/linked/linked/normalized/{lf}', 'r') as csvfile:\n",
    "#        datareader = csv.DictReader(csvfile)\n",
    "#        for row in datareader:\n",
    "#            if row['ID'] == _id:\n",
    "#                yield row\n",
    "\n",
    "#for lf in linked_files:\n",
    "#    for _id in ids:\n",
    "#        for huh in extract_links(lf, _id):\n",
    "#            lines.append(huh)\n",
    "\n",
    "#lines\n",
    "\n",
    "# df = dd.read_csv(\"/home/stephan/src/habeas-corpus/data/czi-software-mentions/linked/linked/normalized/bioconductor_df.csv\")\n",
    "# print(f'EMPTY? {len(df.index)}')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linked_lines = []\n",
    "\n",
    "#with open(f'{DATA_DIR_PATH}/czi_output_random_100.csv', 'r', encoding='utf-8-sig') as csvin:\n",
    "#    csvr = csv.DictReader(csvin, delimiter=',')\n",
    "#    for row in csvr:\n",
    "#        _id = row['ID']\n",
    "#        for line in lines:\n",
    "#            if line['ID'] == _id:\n",
    "#                linked_line = row | line\n",
    "#                linked_lines.append(linked_line)\n",
    "#                continue\n",
    "#        linked_lines.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ceb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#\n",
    "#interim_df = pd.read_json(json.dumps(linked_lines))\n",
    "#interim_df.to_csv(f'{DATA_DIR_PATH}/CZI_sample_1000_without_top_100_linked.csv', encoding='utf-8', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f91c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
